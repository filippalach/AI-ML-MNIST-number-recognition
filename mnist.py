#todo: another logger (both file and stdout)
#      adding reqs

import torch
import torchvision
import json
import logging
import os

with open('config.json') as json_config:
    data = json.load(json_config)

TRAIN_BATCH_SIZE = data['train_batch_size']
TEST_BATCH_SIZE = data['test_batch_size']
EPOCHS = data['epochs']
LOG_INTERVAL = data['log_interval']
OPTIMIZER_LR = data['optimizer_lr']
USE_CUDA = data['use_cuda']
SAVE_MODEL = data['save_model']
SAVE_NAME = data['save_name']
NUM_WORKERS = data['num_workers']
SET_INFO_PATH = data['set_info_path']


class Network(torch.nn.Module):
    """Network class representing neural network model."""

    def __init__(self):
        super().__init__()
        self.first_layer = torch.nn.Linear(28 * 28, 64, bias=True)
        self.second_layer = torch.nn.Linear(64, 64, bias=True)
        self.third_layer = torch.nn.Linear(64, 64, bias=True)
        self.fourth_layer = torch.nn.Linear(64, 10, bias=True)

    def forward(self, x):
        x = torch.nn.functional.relu(self.first_layer(x))
        x = torch.nn.functional.relu(self.second_layer(x))
        x = torch.nn.functional.relu(self.third_layer(x))
        x = self.fourth_layer(x)

        return torch.nn.functional.log_softmax(x, dim=1)


def load_sets(train_batch_size: int, test_batch_size: int) -> (torch.utils.data.DataLoader, torch.utils.data.DataLoader):
    """
    Loads MNIST dataset from torchvision into both train and test data sets.

    :param train_batch_size: train set batch size
    :param test_batch_size: test set batch size

    :return: loaded (train set, loaded test) set (as tuple)
    """

    train_set = torchvision.datasets.MNIST('', train=True, download=True,
                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))

    test_set = torchvision.datasets.MNIST('', train=False, download=True,
                                          transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))

    train_set_loaded = torch.utils.data.DataLoader(train_set, train_batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, timeout=10)
    test_set_loaded = torch.utils.data.DataLoader(test_set, test_batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, timeout=10)

    # sets contain [0] - batch of samples, [1] tensor of numeric values (tensor of tensors)
    return train_set_loaded, test_set_loaded


def train_model(model: Network, train_set_loaded: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer,
                epoch: int, device: torch.device):
    """
    Implements training model, logs info with frequency based on LOG_INTERVAL config variable

    :param model: model instance
    :param train_set_loaded: train set
    :param optimizer: torhc optimizer 
    :param epoch: specifies in which epoch function is in
    :device: device on which model is being run

    :return: does not return
    """

    for batch_index, (x, y) in enumerate(train_set_loaded):
        x, y = x.to(device), y.to(device)
        model.zero_grad()
        output = model(x.view(-1,784))
        loss = torch.nn.functional.nll_loss(output, y)
        loss.backward()
        optimizer.step()
        if batch_index % LOG_INTERVAL == 0:
            logging.info('Epoch: %d [%d/%d] Loss: %f', epoch, batch_index * len(x), len(train_set_loaded.dataset), loss.item())


def test_model(model: Network, test_set_loaded: torch.utils.data.DataLoader, device: torch.device):
    """
    Implements testing model accuracy, compares results generated by trained model. Logs accuracy.

    :param model: model instance
    :param test_set_loaded: test set
    :param device: device on wchich model is being run

    :return: does not return
    """

    correct = 0
    total = 0

    with torch.no_grad():
        for (x, y) in test_set_loaded:
            x, y = x.to(device), y.to(device)
            output = model(x.view(-1,784))
            for idx, i in enumerate(output):
                if torch.argmax(i) == y[idx]:
                    correct += 1
                total += 1
        
        logging.info('Accuracy: %s', round(correct/total, 3))


def MNIST_set_info(set_loaded: torch.utils.data.DataLoader):
    """
    Prints the information about data set based on SET_INFO_PATH file in config.json, or if
    it does not exist, creates such and fill it in with information.

    :param set_loaded: loaded set of data
    """

    if not os.path.exists(SET_INFO_PATH):
        total = 0
        counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}

        for (x, y) in set_loaded:
            for ys in y:
                counter_dict[int(ys)] += 1
                total += 1

        with open(SET_INFO_PATH, 'w') as file:
            for i in counter_dict:
                file.write('{}: {}\n'.format(i, round(counter_dict[i]/total * 100, 3)))
    else:
        with open(SET_INFO_PATH) as file:
            print(file.read())


def main():
    """Implements main program logic."""

    logging.basicConfig(filename='mnist.log', format='%(asctime)s:%(levelname)s:%(message)s', level=logging.DEBUG)

    train_set_loaded, test_set_loaded = load_sets(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE)

    MNIST_set_info(train_set_loaded)

    if USE_CUDA and torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')

    model = Network()

    optimizer = torch.optim.Adam(model.parameters(), lr=OPTIMIZER_LR)

    for epoch in range(1, EPOCHS + 1):
        train_model(model, train_set_loaded, optimizer, epoch, device)
        test_model(model, test_set_loaded, device)

    if SAVE_MODEL:
        torch.save(model.state_dict(), SAVE_NAME)


if __name__ == '__main__':
    main()