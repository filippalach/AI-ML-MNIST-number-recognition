import torch
import torchvision
import json

with open('config.json') as json_config:
    data = json.load(json_config)

TRAIN_BATCH_SIZE = data['train_batch_size']
TEST_BATCH_SIZE = data['test_batch_size']
EPOCHS = data['epochs']
LOG_INTERVAL = data['log_interval']
OPTIMIZER_LR = data['optimizer_lr']
USE_CUDA = data['use_cuda']
SAVE_MODEL = data['save_model']
SAVE_NAME = data['save_name']


class Network(torch.nn.Module):
    """Network class representing neural network model."""

    def __init__(self):
        super().__init__()
        self.first_layer = torch.nn.Linear(28 * 28, 64, bias=True)
        self.second_layer = torch.nn.Linear(64, 64, bias=True)
        self.third_layer = torch.nn.Linear(64, 64, bias=True)
        self.fourth_layer = torch.nn.Linear(64, 10, bias=True)


    def forward(self, x):
        x = torch.nn.functional.relu(self.first_layer(x))
        x = torch.nn.functional.relu(self.second_layer(x))
        x = torch.nn.functional.relu(self.third_layer(x))
        x = self.fourth_layer(x)

        return torch.nn.functional.log_softmax(x, dim=1)


def load_sets(train_batch_size: int, test_batch_size: int) -> (torch.utils.data.DataLoader, torch.utils.data.DataLoader):
    """
    Loads MNIST dataset from torchvision into both train and test data sets.

    :param train_batch_size: train set batch size
    :param test_batch_size: test set batch size

    :return: loaded (train set, loaded test) set (as tuple)
    """

    train_set = torchvision.datasets.MNIST('', train=True, download=True,
                                           transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))

    test_set = torchvision.datasets.MNIST('', train=False, download=True,
                                          transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))

    train_set_loaded = torch.utils.data.DataLoader(train_set, train_batch_size, shuffle=True)
    test_set_loaded = torch.utils.data.DataLoader(test_set, test_batch_size, shuffle=False)

    return train_set_loaded, test_set_loaded


def train_model(model: Network, train_set_loaded: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer,
                epoch: int, device: torch.cuda.device):
    """
    Implements training model, logs info with frequency based on LOG_INTERVAL config variable

    :param model: model instance
    :param train_set_loaded: train set
    :param optimizer: torhc optimizer 
    :param epoch: specifies in which epoch function is in
    :device: device on which model is being run

    :return: does not return
    """

    for batch_index, (x, y) in enumerate(train_set_loaded):  # `data` is a batch of data
        #X, y = data  # X is the batch of features, y is the batch of targets.
        x, y = x.to(device), y.to(device)
        model.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.
        output = model(x.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)
        loss = torch.nn.functional.nll_loss(output, y)  # calc and grab the loss value
        loss.backward()  # apply this loss backwards thru the modelwork's parameters
        optimizer.step()  # attempt to optimize weights to account for loss/gradients
        if batch_index % LOG_INTERVAL == 0:
            print('Epoch: {} [{}/{} ({:.0f}%)] Loss: {}'.format(epoch, batch_index * len(x), len(train_set_loaded.dataset),
                                                                100. * batch_index / len(train_set_loaded), loss.item()))


def test_model(model: Network, test_set_loaded: torch.utils.data.DataLoader, device: torch.cuda.device):
    """
    Implements testing model accuracy, compares results generated by trained model. Logs accuracy.

    :param model: model instance
    :param test_set_loaded: test set
    :param device: device on wchich model is being run

    :return: does not return
    """
    correct = 0
    total = 0
    with torch.no_grad():
        for (x, y) in test_set_loaded:
            #x, y = data
            x, y = x.to(device), y.to(device)
            output = model(x.view(-1,784))
            #print(output)
            for idx, i in enumerate(output):
              #print(torch.argmax(i), y[idx])
                if torch.argmax(i) == y[idx]:
                    correct += 1
                total += 1

        #return 'Accuracy: {}'.format(round(correct/total, 3))
        print("Accuracy: ", round(correct/total, 3))


def use_cuda_if_available(use_cuda: bool) -> (str):
    """
    :param use_cuda: specifies if cuda should be used

    :return: cuda or cpu
    """
    if use_cuda and torch.cuda.is_available():
        return torch.cuda.device("cuda" if use_cuda else "cpu")

def main():
    """Implements main program logic."""

    train_set_loaded, test_set_loaded = load_sets(TRAIN_BATCH_SIZE, TEST_BATCH_SIZE)

    device = use_cuda_if_available(USE_CUDA)

    model = Network()

    optimizer = torch.optim.Adam(model.parameters(), lr=OPTIMIZER_LR)

    for epoch in range(1, EPOCHS + 1):
        train_model(model, train_set_loaded, optimizer, epoch, device)
        print(test_model(model, test_set_loaded, device))

    if SAVE_MODEL:
        torch.save(model.state_dict(), SAVE_NAME)

if __name__ == '__main__':
    main()